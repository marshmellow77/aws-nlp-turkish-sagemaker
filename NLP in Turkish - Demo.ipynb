{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0296adeb",
   "metadata": {},
   "source": [
    "# Teaching a Turkish language model new tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089eb104",
   "metadata": {},
   "source": [
    "Instead of creating a new Machine Learning (ML) model for every new task, we can leverage the concept of *Transfer Learning*. \n",
    "\n",
    "In particular, we can use generic language models and teach it new tasks by fine-tuning them using corresponding datasets. In this notebook we will use a Turkish language model created by the MDZ Digital Library team (dbmdz) at the Bavarian State Library (https://github.com/stefan-it/turkish-bert). We will use the Hugging Face Model Hub to download the model (https://huggingface.co/dbmdz/bert-base-turkish-uncased) and then fine-tune it to 2 very different tasks:\n",
    "\n",
    "- Sentiment Analysis\n",
    "- Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae73b9",
   "metadata": {},
   "source": [
    "## SageMaker Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd941b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7344bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::905847418383:role/service-role/AmazonSageMaker-ExecutionRole-20211005T160629\n",
      "sagemaker bucket: sagemaker-us-east-1-905847418383\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session_bucket}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62096599",
   "metadata": {},
   "source": [
    "#### Define model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9638f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dbmdz/bert-base-turkish-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a24ff",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cea1da",
   "metadata": {},
   "source": [
    "### Downloading dataset and splitting into test and training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ee7da",
   "metadata": {},
   "source": [
    "We will downlaod the data directly from Huggingface: https://huggingface.co/datasets/turkish_product_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4748e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2dc63f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf7f5761afc4aa48bdde63ba15a5245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=880.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1720506e89ed48988f93abeb4db16b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=576.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset turkish_product_reviews/default (download: 12.57 MiB, generated: 41.36 MiB, post-processed: Unknown size, total: 53.93 MiB) to /home/ec2-user/.cache/huggingface/datasets/turkish_product_reviews/default/1.0.0/d9158dc8210baf7a7ea495c26016996f6a27d7cc524ac239e5b8dcedcd292390...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6a56a9f8684ad282e8f0eb9f698959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=13184332.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724e9dbc021d486383ae7a9358083c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset turkish_product_reviews downloaded and prepared to /home/ec2-user/.cache/huggingface/datasets/turkish_product_reviews/default/1.0.0/d9158dc8210baf7a7ea495c26016996f6a27d7cc524ac239e5b8dcedcd292390. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'turkish_product_reviews'\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f46797",
   "metadata": {},
   "source": [
    "We will only take 10% of the data to reduce training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a8c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f1f52e",
   "metadata": {},
   "source": [
    "Now we split the data into training set (90%) and test set (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b576e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sample['test']\n",
    "train_test = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_test['train']\n",
    "test_dataset = train_test['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ad3bb",
   "metadata": {},
   "source": [
    "Now we can inspect the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75170e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2574119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['sentence', 'labels']].iloc[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe57267",
   "metadata": {},
   "source": [
    "Before we can start the training we need to tokenize the data save it in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de77dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3178fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = 'datasets/turkish_product_reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0944111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()  \n",
    "\n",
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sagemaker_session_bucket}/{s3_prefix}/train'\n",
    "train_dataset.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "test_input_path = f's3://{sagemaker_session_bucket}/{s3_prefix}/test'\n",
    "test_dataset.save_to_disk(test_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036427a6",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 8,\n",
    "                 'model_name': model_name\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ad91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_sentiment = HuggingFace(entry_point='train.py',\n",
    "                                    source_dir='./scripts',\n",
    "                                    instance_type='ml.p3.2xlarge',\n",
    "                                    instance_count=1,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.6',\n",
    "                                    pytorch_version='1.7',\n",
    "                                    py_version='py36',\n",
    "                                    hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94280b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_sentiment.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d03dc69",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84173800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker \n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model_sentiment = HuggingFaceModel(\n",
    "   model_data= f\"s3://{sagemaker_session_bucket}/huggingface-pytorch-training-2021-10-01-16-52-39-333/output/model.tar.gz\",\n",
    "   role=role,\n",
    "   transformers_version=\"4.6\", \n",
    "   pytorch_version=\"1.7\", \n",
    "   py_version=\"py36\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7231c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "predictor_sentiment = huggingface_model_sentiment.deploy(1, \"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0b283",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df106b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9829983711242676}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input text: \"This is a pretty bad product, I wouldn't recommend this to anyone\"\n",
    "sentiment_input= {\"inputs\": \"Bu oldukça kötü bir ürün, bunu kimseye tavsiye etmem\"}\n",
    "predictor_sentiment.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3c2f09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9976404905319214}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input text: \"I love this shampoo, it makes my hair so shiny\"\n",
    "sentiment_input= {\"inputs\": \"Bu şampuanı seviyorum, saçlarımı çok parlak yapıyor\"}\n",
    "predictor_sentiment.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb7b32",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928c0c9c",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    "\n",
    "Taken from https://github.com/TQuad/turkish-nlp-qa-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998339fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/TQuad/turkish-nlp-qa-dataset/master/train-v0.1.json data/train-v0.1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/TQuad/turkish-nlp-qa-dataset/master/dev-v0.1.json data/dev-v0.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e840f60",
   "metadata": {},
   "source": [
    "The JSON files must be converted so that they can be used in a Q&A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50590ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "def convert_json(input_filename, output_filename):\n",
    "    with open(input_filename) as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        for article in dataset[\"data\"]:\n",
    "            title = article[\"title\"]\n",
    "            for paragraph in article[\"paragraphs\"]:\n",
    "                context = paragraph[\"context\"]\n",
    "                answers = {}\n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    question = qa[\"question\"]\n",
    "                    idx = qa[\"id\"]\n",
    "                    answers[\"text\"] = [a[\"text\"] for a in qa[\"answers\"]]\n",
    "                    answers[\"answer_start\"] = [int(a[\"answer_start\"]) for a in qa[\"answers\"]]\n",
    "                    f.write(\n",
    "                        json.dumps(\n",
    "                            {\n",
    "                                \"id\": idx,\n",
    "                                \"title\": title,\n",
    "                                \"context\": context,\n",
    "                                \"question\": question,\n",
    "                                \"answers\": answers,\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c34e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_json('data/train-v0.1.json', 'data/train.json')\n",
    "convert_json('data/dev-v0.1.json', 'data/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23a439d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {}\n",
    "data_files[\"train\"] = 'data/train.json'\n",
    "data_files[\"validation\"] = 'data/val.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de262363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8dc8d5e84c5485b6\n",
      "Reusing dataset json (/home/ec2-user/.cache/huggingface/datasets/json/default-8dc8d5e84c5485b6/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f5544cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "213e274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>8348</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi'nin kurulma amacı nedir?</td>\n",
       "      <td>{'text': [' Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması '], 'answer_start': [75]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>8349</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevinin ne gibi amaçları vardır?</td>\n",
       "      <td>{'text': ['Gerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak'], 'answer_start': [661]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>8350</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi hangi amaçla açılmıştır?</td>\n",
       "      <td>{'text': ['Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla'], 'answer_start': [76]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                            title  \\\n",
       "7518  8348  İstanbul Üniversitesi Gözlemevi   \n",
       "7519  8349  İstanbul Üniversitesi Gözlemevi   \n",
       "7520  8350  İstanbul Üniversitesi Gözlemevi   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         context  \\\n",
       "7518  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "7519  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "7520  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "\n",
       "                                                                                    question  \\\n",
       "7518  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi'nin kurulma amacı nedir?   \n",
       "7519  İstanbul Üniversitesi Gözlemevinin ne gibi amaçları vardır?                              \n",
       "7520  İstanbul Üniversitesi Gözlemevi hangi amaçla açılmıştır?                                 \n",
       "\n",
       "                                                                                                                                                                                                                    answers  \n",
       "7518  {'text': [' Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması '], 'answer_start': [75]}                                                                  \n",
       "7519  {'text': ['Gerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak'], 'answer_start': [661]}  \n",
       "7520  {'text': ['Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla'], 'answer_start': [76]}                                                           "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[7518:7521]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9788eb6",
   "metadata": {},
   "source": [
    "Uploading to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34591486",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = 'datasets/turkish_qa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp data/train.json s3://$sagemaker_session_bucket/$s3_prefix/train.json\n",
    "!aws s3 cp data/val.json s3://$sagemaker_session_bucket/$s3_prefix/val.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6adf5",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "hyperparameters={\n",
    "    'model_name_or_path': model_name,\n",
    "    'train_file': '/opt/ml/input/data/train/train.json',\n",
    "    'validation_file': '/opt/ml/input/data/val/val.json',\n",
    "    'do_train': True,\n",
    "    'do_eval': False,\n",
    "    'fp16': True,\n",
    "    'per_device_train_batch_size': 4,\n",
    "    'per_device_eval_batch_size': 4,\n",
    "    'num_train_epochs': 2,\n",
    "    'max_seq_length': 384,\n",
    "    'pad_to_max_length': True,\n",
    "    'doc_stride': 128,\n",
    "    'output_dir': '/opt/ml/model'\n",
    "}\n",
    "\n",
    "instance_type = 'ml.p3.16xlarge'\n",
    "instance_count = 1\n",
    "volume_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c86d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='run_qa.py',\n",
    "                                    source_dir='./scripts',\n",
    "                                    instance_type=instance_type,\n",
    "                                    instance_count=instance_count,\n",
    "                                    volume_size=volume_size,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.10',\n",
    "                                    pytorch_version='1.9',\n",
    "                                    py_version='py38',\n",
    "                                    hyperparameters= hyperparameters,\n",
    "                                    disable_profiler=True,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78db45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit({'train': f's3://{sagemaker_session_bucket}/{s3_prefix}/', 'val': f's3://{sagemaker_session_bucket}/{s3_prefix}/'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678f9c0",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abfa138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker \n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model_qa = HuggingFaceModel(\n",
    "   model_data=\"s3://sagemaker-us-east-1-905847418383/huggingface-pytorch-training-2021-10-12-05-07-28-087/output/model.tar.gz\",\n",
    "   role=role, # \n",
    "   transformers_version=\"4.10\", \n",
    "   pytorch_version=\"1.9\", \n",
    "   py_version=\"py38\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da15a0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor_qa = huggingface_model_qa.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68919e",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76debfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Babasının ölümü üzerine'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question: \"When did he start a vagabond life?\"\n",
    "#Predicted answer: \"On his father's death\"\n",
    "\n",
    "data = {\n",
    "\"inputs\": {\n",
    "    \"question\": \"Ne zaman avare bir hayata başladı?\",\n",
    "    \"context\": \"\"\"ABASIYANIK, Sait Faik. Hikayeci (Adapazarı 23 Kasım 1906-İstanbul 11 Mayıs 1954). \\\n",
    "İlk öğrenimine Adapazarı’nda Rehber-i Terakki Mektebi’nde başladı. İki yıl kadar Adapazarı İdadisi’nde okudu.\\\n",
    "İstanbul Erkek Lisesi’nde devam ettiği orta öğrenimini Bursa Lisesi’nde tamamladı (1928). İstanbul Edebiyat \\\n",
    "Fakültesi’ne iki yıl devam ettikten sonra babasının isteği üzerine iktisat öğrenimi için İsviçre’ye gitti. \\\n",
    "Kısa süre sonra iktisat öğrenimini bırakarak Lozan’dan Grenoble’a geçti. Üç yıl başıboş bir edebiyat öğrenimi \\\n",
    "gördükten sonra babası tarafından geri çağrıldı (1933). Bir müddet Halıcıoğlu Ermeni Yetim Mektebi'nde Türkçe \\\n",
    "gurup dersleri öğretmenliği yaptı. Ticarete atıldıysa da tutunamadı. Bir ay Haber gazetesinde adliye muhabirliği\\\n",
    "yaptı (1942). Babasının ölümü üzerine aileden kalan emlakin geliri ile avare bir hayata başladı. Evlenemedi.\\\n",
    "Yazları Burgaz adasındaki köşklerinde, kışları Şişli’deki apartmanlarında annesi ile beraber geçen bu fazla \\\n",
    "içkili bohem hayatı ömrünün sonuna kadar sürdü.\"\"\"\n",
    "    }\n",
    "}\n",
    "predictor_qa.predict(data)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "019b42a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nazi Partisi'nin     iktidara yükselişi nedeniyle\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question: \"Why did Einstein leave Germany?\"\n",
    "#Predicted answer: \"Due to the rise to power of the Nazi Party\"\n",
    "\n",
    "data = {\n",
    "\"inputs\": {\n",
    "    \"question\": \"Einstein Almanya'dan neden ayrıldı?\",\n",
    "    \"context\": \"\"\"Alman İmparatorluğu'nun Ulm kentinde, Aşkenazi Yahudi bir ailede dünyaya gelen Einstein, \\ \n",
    "    yaşamının ilk yıllarını Münih'te geçirdi. Lise eğitimini ve yüksek eğitimini İsviçre'de tamamladı; fakat \\\n",
    "    bir üniversitede iş bulmada yaşadığı zorluklar nedeniyle bir patent ofisinde müfettiş olarak çalışmaya başladı. \\\n",
    "    1905 yılı Einstein için bir mucize yıl oldu ve o dönemde kuramları hemen benimsenmemiş olsa da ileride fizikte \\\n",
    "    devrim yaratacak olan dört makale yayımladı. 1914 yılında Max Planck'ın kişisel ricası ile Almanya'ya geri döndü. \\\n",
    "    1921 yılında fotoelektrik etki üzerine çalışmaları nedeniyle Nobel Fizik Ödülü'ne layık görüldü. Nazi Partisi'nin \\\n",
    "    iktidara yükselişi nedeniyle 1933'te Almanya'yı terk etti ve Amerika Birleşik Devletleri'ne yerleşti. Ömrünün geri \\\n",
    "    kalanını geçirdiği New Jersey eyaletinin Princeton ilçesinde ölmüştür. \"\"\"\n",
    "    }\n",
    "}\n",
    "predictor_qa.predict(data)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc3783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p37",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
