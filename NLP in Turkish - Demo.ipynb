{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving NLP (Natural Language Processing) Problems with HuggingFace Library on AWS for Turkish Language\n",
    "## Use Case\n",
    "In this demo, we will demonstrate two NLP use cases.\n",
    "- _Sentiment Analysis:_ You can find positive, negative and neutral mentions about your business, competitors or any topic provided as text to the Machine Learning model.\n",
    "- _Question Answering:_ Question-Answering Models are  deep learning models that can answer questions given some context, and sometimes without any context (e.g. open-domain QA). They can extract answer phrases from paragraphs, paraphrase the answer generatively, or choose one option out of a list of given options, and so on.\n",
    "## Dataset\n",
    "We will use following datasets:\n",
    "- _Dataset Card for Turkish Product Reviews:_ This Turkish Product Reviews Dataset contains 235.165 product reviews collected online. There are 220.284 positive, 14881 negative reviews.\n",
    "- _Turkish NLP Q&A Dataset:_ This dataset is the Turkish Question & Answer dataset on Turkish Science History.\n",
    "## Approach\n",
    "Instead of creating a new Machine Learning (ML) model for every new task, we can leverage the concept of *Transfer Learning*.\n",
    "In particular, we can use generic language models and teach it new tasks by fine-tuning them using corresponding datasets.\n",
    "In this notebook we will use a Turkish language model created by the MDZ Digital Library team (dbmdz) at the Bavarian State Library (https://github.com/stefan-it/turkish-bert). We will use the Hugging Face Model Hub to download the model (https://huggingface.co/dbmdz/bert-base-turkish-uncased) and then fine-tune it to two  different tasks. We will deploy to SageMaker for real-time inferencing.\n",
    "- Sentiment Analysis: We will see how the fine tuned model achieves SoTA (State of the Art) performance for Sentiment Analysis for Turkish easily.\n",
    "- Question Answering:\n",
    "## How to Run this Notebook in Amazon SageMaker\n",
    "You can run this notebook in SageMaker Studio. Please select the `PyTorch 1.6 Python 3.6 CPU Optimized` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.6m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.6m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.6m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.6m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.6m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.6m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets IProgress -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::905847418383:role/service-role/AmazonSageMaker-ExecutionRole-20211005T160629\n",
      "sagemaker bucket: sagemaker-us-east-1-905847418383\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session_bucket}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dbmdz/bert-base-turkish-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset and splitting into test and training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will downlaod the data directly from Huggingface: https://huggingface.co/datasets/turkish_product_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sagemaker.huggingface.model import HuggingFacePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset turkish_product_reviews (/root/.cache/huggingface/datasets/turkish_product_reviews/default/1.0.0/9cc21a14e05e4117ea24b5b916effe55cbc88278441c21e03d3807c9bda2219d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ac3c87c64a4ad6b4d886adbb29aa9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = 'turkish_product_reviews'\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only take 10% of the data to reduce training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/turkish_product_reviews/default/1.0.0/9cc21a14e05e4117ea24b5b916effe55cbc88278441c21e03d3807c9bda2219d/cache-e288b41d27d0be32.arrow and /root/.cache/huggingface/datasets/turkish_product_reviews/default/1.0.0/9cc21a14e05e4117ea24b5b916effe55cbc88278441c21e03d3807c9bda2219d/cache-23a73b75b8b53465.arrow\n"
     ]
    }
   ],
   "source": [
    "sample = dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into training set (90%) and test set (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sample['test']\n",
    "train_test = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_test['train']\n",
    "test_dataset = train_test['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can inspect the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ön kamera deliği yok, hissiyat güzel, parmak izi yapıyor, fiyatı uygun, 6s için yanlarda yer kalıyor. bu fiyata alınır</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ürün elime 2 günde geçti geldiğinde şarjı yoktu şarjı pc'den 2 saatte doldu. kullanımı çok basit. uygulama üzerinden ayarlarımı açtım ve 10 gündür kullanıyorum. ***arayan ve mesaj atan kimliğini göstermesi çok işime yarıyor. adımsayarını spor yaparken kullanıyorum. şarjı iş yerimde ve otobüste sürekli telefona bağlı olmasına rağmen 10 günde %77e düştü. zaten akıllı bileklik araştırırken şarjı ön planda tutmuştum. size tavsiyem sipariş verirken cam filmi de isteyin. i̇çiniz daha rahat eder. ayrıca sadece adımsayar özelliği için  bilekliği telefona sürekli bağlamak zorunda değilsiniz. günde 1 kez eşleştirseniz bilgiler uygulamaya geçiyor.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>evet aldım fakat sadece arkadan kilitleniyor bununda pek anlamı yok çünkü elde götürme olasılığın yok bu nedenle aldığıma biraz pişmanım</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>harika demek az kalır ne diyeceğimi bilmiyorum... katı meyveleri 1 saniyede püre yapıyor, sıvı bir şey hazırlayacaksanız 1 damla damlatmıyor... dün geldi yıkadım bugün hemen bebeğime meyve püresi, muzlu süt ve muffin hazırladım... açıkçası zorladım makinayı ve testlerimden başarıyla geçti... teşekkürler philips, verdiğim paraya fazlasıyla değdi :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iyi alışveriş hızlı kargo, fiyat performans açısından gayet başarılı bir cihaz, tavsiye ederim..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                sentence  \\\n",
       "10  ön kamera deliği yok, hissiyat güzel, parmak izi yapıyor, fiyatı uygun, 6s için yanlarda yer kalıyor. bu fiyata alınır                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "11  ürün elime 2 günde geçti geldiğinde şarjı yoktu şarjı pc'den 2 saatte doldu. kullanımı çok basit. uygulama üzerinden ayarlarımı açtım ve 10 gündür kullanıyorum. ***arayan ve mesaj atan kimliğini göstermesi çok işime yarıyor. adımsayarını spor yaparken kullanıyorum. şarjı iş yerimde ve otobüste sürekli telefona bağlı olmasına rağmen 10 günde %77e düştü. zaten akıllı bileklik araştırırken şarjı ön planda tutmuştum. size tavsiyem sipariş verirken cam filmi de isteyin. i̇çiniz daha rahat eder. ayrıca sadece adımsayar özelliği için  bilekliği telefona sürekli bağlamak zorunda değilsiniz. günde 1 kez eşleştirseniz bilgiler uygulamaya geçiyor.   \n",
       "12  evet aldım fakat sadece arkadan kilitleniyor bununda pek anlamı yok çünkü elde götürme olasılığın yok bu nedenle aldığıma biraz pişmanım                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "13  harika demek az kalır ne diyeceğimi bilmiyorum... katı meyveleri 1 saniyede püre yapıyor, sıvı bir şey hazırlayacaksanız 1 damla damlatmıyor... dün geldi yıkadım bugün hemen bebeğime meyve püresi, muzlu süt ve muffin hazırladım... açıkçası zorladım makinayı ve testlerimden başarıyla geçti... teşekkürler philips, verdiğim paraya fazlasıyla değdi :)                                                                                                                                                                                                                                                                                                          \n",
       "14  iyi alışveriş hızlı kargo, fiyat performans açısından gayet başarılı bir cihaz, tavsiye ederim..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "    sentiment  \n",
       "10  1          \n",
       "11  1          \n",
       "12  0          \n",
       "13  1          \n",
       "14  1          "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['sentence', 'sentiment']].iloc[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start the training we need to tokenize the data save it in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3b526480d3498987e2bf5292791494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0121e1aabec45498dc7b65e66adcafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =  train_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset = test_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix_sentiment = 'datasets/turkish_product_reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()  \n",
    "\n",
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sagemaker_session_bucket}/{s3_prefix_sentiment}/train'\n",
    "train_dataset.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "test_input_path = f's3://{sagemaker_session_bucket}/{s3_prefix_sentiment}/test'\n",
    "test_dataset.save_to_disk(test_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'sentence', 'labels', 'token_type_ids'],\n",
       "    num_rows: 21165\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters_sentiment={'epochs': 1,\n",
    "                 'train_batch_size': 8,\n",
    "                 'model_name': model_name\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_sentiment = HuggingFace(entry_point='train.py',\n",
    "                                    source_dir='./scripts',\n",
    "                                    instance_type='ml.p3.2xlarge',\n",
    "                                    instance_count=1,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.6',\n",
    "                                    pytorch_version='1.7',\n",
    "                                    py_version='py36',\n",
    "                                    hyperparameters=hyperparameters_sentiment,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_sentiment.fit({'train': training_input_path, 'test': test_input_path}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ModelArtifacts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7af137c5e87e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ml.m5.xlarge\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"turkish_sentiment\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, use_compiled_model, wait, model_name, kms_key, data_capture_config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_kms_key\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_kms_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/huggingface/estimator.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(self, model_server_workers, role, vpc_config_override, entry_point, source_dir, dependencies, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         return HuggingFaceModel(\n\u001b[1;32m    275\u001b[0m             \u001b[0mrole\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mmodel_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mentry_point\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mtransformers_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mmodel_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             model_uri = self.sagemaker_session.sagemaker_client.describe_training_job(\n\u001b[1;32m   1045\u001b[0m                 \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             )[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n\u001b[0m\u001b[1;32m   1047\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             logger.warning(\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ModelArtifacts'"
     ]
    }
   ],
   "source": [
    "predictor_sentiment = huggingface_estimator_sentiment.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    wait=False,\n",
    "    endpoint_name=\"turkish-sentiment-endpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only required to create a predictor from an already deployed model\n",
    "predictor_sentiment = HuggingFacePredictor('huggingface-pytorch-inference-2021-10-17-14-15-24-043')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9829983711242676}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input text: \"This is a pretty bad product, I wouldn't recommend this to anyone\"\n",
    "sentiment_input= {\"inputs\": \"Bu oldukça kötü bir ürün, bunu kimseye tavsiye etmem\"}\n",
    "predictor_sentiment.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9976404905319214}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input text: \"I love this shampoo, it makes my hair so shiny\"\n",
    "sentiment_input= {\"inputs\": \"Bu şampuanı seviyorum, saçlarımı çok parlak yapıyor\"}\n",
    "predictor_sentiment.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    "\n",
    "Taken from https://github.com/TQuad/turkish-nlp-qa-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/TQuad/turkish-nlp-qa-dataset/master/train-v0.1.json -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/TQuad/turkish-nlp-qa-dataset/master/dev-v0.1.json -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv train-v0.1.json data/train-v0.1.json\n",
    "!mv dev-v0.1.json data/dev-v0.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON files must be converted so that they can be used in a Q&A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "def convert_json(input_filename, output_filename):\n",
    "    with open(input_filename) as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        for article in dataset[\"data\"]:\n",
    "            title = article[\"title\"]\n",
    "            for paragraph in article[\"paragraphs\"]:\n",
    "                context = paragraph[\"context\"]\n",
    "                answers = {}\n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    question = qa[\"question\"]\n",
    "                    idx = qa[\"id\"]\n",
    "                    answers[\"text\"] = [a[\"text\"] for a in qa[\"answers\"]]\n",
    "                    answers[\"answer_start\"] = [int(a[\"answer_start\"]) for a in qa[\"answers\"]]\n",
    "                    f.write(\n",
    "                        json.dumps(\n",
    "                            {\n",
    "                                \"id\": idx,\n",
    "                                \"title\": title,\n",
    "                                \"context\": context,\n",
    "                                \"question\": question,\n",
    "                                \"answers\": answers,\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_json('data/train-v0.1.json', 'data/train.json')\n",
    "convert_json('data/dev-v0.1.json', 'data/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {}\n",
    "data_files[\"train\"] = 'data/train.json'\n",
    "data_files[\"validation\"] = 'data/val.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c1c6b7140e527524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-c1c6b7140e527524/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14b87e08d724dc8a727d426918db5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55051421004489d9f574a2ab4ea112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-c1c6b7140e527524/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b17c541f8a54fa7856d046447a9fa8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>8348</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi'nin kurulma amacı nedir?</td>\n",
       "      <td>{'text': [' Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması '], 'answer_start': [75]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>8349</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevinin ne gibi amaçları vardır?</td>\n",
       "      <td>{'text': ['Gerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak'], 'answer_start': [661]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>8350</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi hangi amaçla açılmıştır?</td>\n",
       "      <td>{'text': ['Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla'], 'answer_start': [76]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                            title  \\\n",
       "7518  8348  İstanbul Üniversitesi Gözlemevi   \n",
       "7519  8349  İstanbul Üniversitesi Gözlemevi   \n",
       "7520  8350  İstanbul Üniversitesi Gözlemevi   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         context  \\\n",
       "7518  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "7519  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "7520  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "\n",
       "                                                                                    question  \\\n",
       "7518  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi'nin kurulma amacı nedir?   \n",
       "7519  İstanbul Üniversitesi Gözlemevinin ne gibi amaçları vardır?                              \n",
       "7520  İstanbul Üniversitesi Gözlemevi hangi amaçla açılmıştır?                                 \n",
       "\n",
       "                                                                                                                                                                                                                    answers  \n",
       "7518  {'text': [' Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması '], 'answer_start': [75]}                                                                  \n",
       "7519  {'text': ['Gerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak'], 'answer_start': [661]}  \n",
       "7520  {'text': ['Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla'], 'answer_start': [76]}                                                           "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[7518:7521]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix_qa = 'datasets/turkish_qa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload failed: data/train.json to s3:////train.json Parameter validation failed:\n",
      "Invalid bucket name \"\": Bucket name must match the regex \"^[a-zA-Z0-9.\\-_]{1,255}$\" or be an ARN matching the regex \"^arn:(aws).*:(s3|s3-object-lambda):[a-z\\-0-9]+:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\\-]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\\-]{1,63}$\"\n",
      "upload failed: data/val.json to s3:////val.json Parameter validation failed:\n",
      "Invalid bucket name \"\": Bucket name must match the regex \"^[a-zA-Z0-9.\\-_]{1,255}$\" or be an ARN matching the regex \"^arn:(aws).*:(s3|s3-object-lambda):[a-z\\-0-9]+:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\\-]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\\-]{1,63}$\"\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp data/train.json s3://$sagemaker_session_bucket/$s3_prefix/train.json\n",
    "!aws s3 cp data/val.json s3://$sagemaker_session_bucket/$s3_prefix/val.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "hyperparameters_qa={\n",
    "    'model_name_or_path': model_name,\n",
    "    'train_file': '/opt/ml/input/data/train/train.json',\n",
    "    'validation_file': '/opt/ml/input/data/val/val.json',\n",
    "    'do_train': True,\n",
    "    'do_eval': False,\n",
    "    'fp16': True,\n",
    "    'per_device_train_batch_size': 4,\n",
    "    'per_device_eval_batch_size': 4,\n",
    "    'num_train_epochs': 2,\n",
    "    'max_seq_length': 384,\n",
    "    'pad_to_max_length': True,\n",
    "    'doc_stride': 128,\n",
    "    'output_dir': '/opt/ml/model'\n",
    "}\n",
    "\n",
    "instance_type = 'ml.p3.16xlarge'\n",
    "instance_count = 1\n",
    "volume_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_qa = HuggingFace(entry_point='run_qa.py',\n",
    "                                       source_dir='./scripts',\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       volume_size=volume_size,\n",
    "                                       role=role,\n",
    "                                       transformers_version='4.10',\n",
    "                                       pytorch_version='1.9',\n",
    "                                       py_version='py38',\n",
    "                                       hyperparameters=hyperparameters_qa,\n",
    "                                       disable_profiler=True,\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_qa.fit({'train': f's3://{sagemaker_session_bucket}/{s3_prefix_qa}/', 'val': f's3://{sagemaker_session_bucket}/{s3_prefix_qa}/'}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_qa = huggingface_estimator_qa.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    wait=False,\n",
    "    endpoint_name=\"turkish-qa-endpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only required to create a predictor from an already deployed model\n",
    "predictor_qa = HuggingFacePredictor('turkish-qa-endpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Babasının ölümü üzerine'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question: \"When did he start a vagabond life?\"\n",
    "#Predicted answer: \"On his father's death\"\n",
    "\n",
    "data = {\n",
    "\"inputs\": {\n",
    "    \"question\": \"Ne zaman avare bir hayata başladı?\",\n",
    "    \"context\": \"\"\"ABASIYANIK, Sait Faik. Hikayeci (Adapazarı 23 Kasım 1906-İstanbul 11 Mayıs 1954). \\\n",
    "İlk öğrenimine Adapazarı’nda Rehber-i Terakki Mektebi’nde başladı. İki yıl kadar Adapazarı İdadisi’nde okudu.\\\n",
    "İstanbul Erkek Lisesi’nde devam ettiği orta öğrenimini Bursa Lisesi’nde tamamladı (1928). İstanbul Edebiyat \\\n",
    "Fakültesi’ne iki yıl devam ettikten sonra babasının isteği üzerine iktisat öğrenimi için İsviçre’ye gitti. \\\n",
    "Kısa süre sonra iktisat öğrenimini bırakarak Lozan’dan Grenoble’a geçti. Üç yıl başıboş bir edebiyat öğrenimi \\\n",
    "gördükten sonra babası tarafından geri çağrıldı (1933). Bir müddet Halıcıoğlu Ermeni Yetim Mektebi'nde Türkçe \\\n",
    "gurup dersleri öğretmenliği yaptı. Ticarete atıldıysa da tutunamadı. Bir ay Haber gazetesinde adliye muhabirliği\\\n",
    "yaptı (1942). Babasının ölümü üzerine aileden kalan emlakin geliri ile avare bir hayata başladı. Evlenemedi.\\\n",
    "Yazları Burgaz adasındaki köşklerinde, kışları Şişli’deki apartmanlarında annesi ile beraber geçen bu fazla \\\n",
    "içkili bohem hayatı ömrünün sonuna kadar sürdü.\"\"\"\n",
    "    }\n",
    "}\n",
    "predictor_qa.predict(data)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1914'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question: \"When did Einstein return to Germany?\"\n",
    "#Predicted answer: \"1914\"\n",
    "\n",
    "data = {\n",
    "\"inputs\": {\n",
    "    \"question\": \"Ne zaman Almanya’ya döndü?\",\n",
    "    \"context\": \"\"\"1908’de artık oldukça tanınmış, büyük bir bilim adamı olarak tanınıyordu ve Bern \\\n",
    "Üniversitesinde öğretmen olarak atanmıştı. Sonraki sene patent ofisindeki işinden ve öğretmenlikten \\\n",
    "ayrıldı ve Zürih Üniversitesinde fizik doçentliğine başladı. 1911 yılında Prag’da Karl-Ferdinand \\\n",
    "Üniversitesinde profesörlük unvanı aldı. 1914 yılında Almanya’ya döndü, Kaiser Willhelm Fizik \\\n",
    "Enstitüsü’nde yönetici, Berlin Humboldt Üniversitesinde profesör oldu. Bu işlerindeki \\\n",
    "sözleşmelerinde öğretmenlik görevlerini oldukça azaltan maddeler vardı.\"\"\"\n",
    "    }\n",
    "}\n",
    "predictor_qa.predict(data)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
