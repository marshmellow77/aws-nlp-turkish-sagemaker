{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving NLP (Natural Language Processing) Problems with HuggingFace Library on AWS for Turkish Language\n",
    "\n",
    "## Use Case\n",
    "In this demo, we will demonstrate two NLP use cases.\n",
    "- _Sentiment Analysis:_ You can find positive, negative and neutral mentions about your business, competitors or any topic provided as text to the Machine Learning model.\n",
    "- _Question Answering:_ Question-Answering Models are  deep learning models that can answer questions given some context, and sometimes without any context (e.g. open-domain QA). They can extract answer phrases from paragraphs, paraphrase the answer generatively, or choose one option out of a list of given options, and so on.\n",
    "\n",
    "## Dataset\n",
    "We will use following datasets:\n",
    "- _Dataset Card for Turkish Product Reviews:_ This Turkish Product Reviews Dataset contains 235.165 product reviews collected online. There are 220.284 positive, 14881 negative reviews.\n",
    "- _Turkish NLP Q&A Dataset:_ This dataset is the Turkish Question & Answer dataset on Turkish Science History.\n",
    "\n",
    "## Approach\n",
    "Instead of creating a new Machine Learning (ML) model for every new task, we can leverage the concept of *Transfer Learning*.\n",
    "In particular, we can use generic language models and teach it new tasks by fine-tuning them using corresponding datasets.\n",
    "In this notebook we will use a Turkish language model created by the MDZ Digital Library team (dbmdz) at the Bavarian State Library (https://github.com/stefan-it/turkish-bert). We will use the Hugging Face Model Hub to download the model (https://huggingface.co/dbmdz/bert-base-turkish-uncased) and then fine-tune it to two  different tasks. We will deploy to SageMaker for real-time inferencing.\n",
    "- Sentiment Analysis: We will see how the fine tuned model achieves SoTA (State of the Art) performance for Sentiment Analysis for Turkish easily.\n",
    "- Question Answering:\n",
    "\n",
    "## How to Run this Notebook in Amazon SageMaker\n",
    "You can run this notebook in SageMaker Studio. Please select the `PyTorch 1.6 Python 3.6 CPU Optimized` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets IProgress -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::905847418383:role/service-role/AmazonSageMaker-ExecutionRole-20211005T160629\n",
      "sagemaker bucket: sagemaker-us-east-1-905847418383\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session_bucket}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dbmdz/bert-base-turkish-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset and splitting into test and training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will downlaod the data directly from Huggingface: https://huggingface.co/datasets/turkish_product_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sagemaker.huggingface.model import HuggingFacePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset turkish_product_reviews (/root/.cache/huggingface/datasets/turkish_product_reviews/default/1.0.0/9cc21a14e05e4117ea24b5b916effe55cbc88278441c21e03d3807c9bda2219d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8eddfd53054a2dbaa3b6d0e63cee54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = 'turkish_product_reviews'\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only take 10% of the data to reduce training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into training set (90%) and test set (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sample['test']\n",
    "train_test = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_test['train']\n",
    "test_dataset = train_test['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can inspect the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inspect = pd.concat([df_train[df_train['sentiment']==0].head(3), df_train[df_train['sentiment']==1].head(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>çok kullanışlı değil benim hoşuma gitmedi.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>almanın bi anlamı yok hiç te anlatıldığı gibi değil ne ses çıkarıyor nede dikkat cekiyor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tasarım güzel ama arka kamera içeride olsa ve küçük olsa daha iyi olur kamera büyük ve dışarda çabuk zarar gördü kamerası kılıf kullanmama rağmen arka kapak çatladı cep hizasından düştü</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gayet i̇yi̇</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>telefonu eşime doğum günü hediyesi olarak aldım ve hediyesini aldığı günden beri elinden düşürmüyor hakikaten çok kullanışlı ve hızlı bir telefon eğer bu telefonu almak isteyip de ikilem de kalanlar var ise hiç düşünmeden mutlaka alsınlar derim. çünkü her türlü özelliğe sahip.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bence başarili bi̇r satici ürün 2. gün eli̇me ulaşti kurulumu çok basi̇t eli̇ni̇ze emeği̇ni̇ze sağlik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                 sentence  \\\n",
       "29  çok kullanışlı değil benim hoşuma gitmedi.                                                                                                                                                                                                                                              \n",
       "54  almanın bi anlamı yok hiç te anlatıldığı gibi değil ne ses çıkarıyor nede dikkat cekiyor                                                                                                                                                                                                \n",
       "68  tasarım güzel ama arka kamera içeride olsa ve küçük olsa daha iyi olur kamera büyük ve dışarda çabuk zarar gördü kamerası kılıf kullanmama rağmen arka kapak çatladı cep hizasından düştü                                                                                               \n",
       "0   gayet i̇yi̇                                                                                                                                                                                                                                                                             \n",
       "1   telefonu eşime doğum günü hediyesi olarak aldım ve hediyesini aldığı günden beri elinden düşürmüyor hakikaten çok kullanışlı ve hızlı bir telefon eğer bu telefonu almak isteyip de ikilem de kalanlar var ise hiç düşünmeden mutlaka alsınlar derim. çünkü her türlü özelliğe sahip.   \n",
       "2   bence başarili bi̇r satici ürün 2. gün eli̇me ulaşti kurulumu çok basi̇t eli̇ni̇ze emeği̇ni̇ze sağlik                                                                                                                                                                                   \n",
       "\n",
       "    sentiment  \n",
       "29  0          \n",
       "54  0          \n",
       "68  0          \n",
       "0   1          \n",
       "1   1          \n",
       "2   1          "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start the training we need to tokenize the data save it in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6507d7154f48fabf77d4e2ff19c4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35101e73d52346449697104a242ead97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =  train_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset = test_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix_sentiment = 'datasets/turkish_product_reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()  \n",
    "\n",
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sagemaker_session_bucket}/{s3_prefix_sentiment}/train'\n",
    "train_dataset.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "test_input_path = f's3://{sagemaker_session_bucket}/{s3_prefix_sentiment}/test'\n",
    "test_dataset.save_to_disk(test_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters_sentiment={'epochs': 1,\n",
    "                 'train_batch_size': 8,\n",
    "                 'model_name': model_name\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_sentiment = HuggingFace(entry_point='train.py',\n",
    "                                    source_dir='./scripts',\n",
    "                                    instance_type='ml.p3.2xlarge',\n",
    "                                    instance_count=1,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.6',\n",
    "                                    pytorch_version='1.7',\n",
    "                                    py_version='py36',\n",
    "                                    hyperparameters=hyperparameters_sentiment,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_sentiment.fit({'train': training_input_path, 'test': test_input_path}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_sentiment = huggingface_estimator_sentiment.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    wait=False,\n",
    "    endpoint_name=\"turkish-sentiment-endpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only required to create a predictor from an already deployed model\n",
    "predictor_sentiment = HuggingFacePredictor('turkish-sentiment-endpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9701817631721497}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input text: \"This is a pretty bad product, I wouldn't recommend this to anyone\"\n",
    "sentiment_input= {\"inputs\": \"Bu oldukça kötü bir ürün, bunu kimseye tavsiye etmem\"}\n",
    "predictor_sentiment.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9980107545852661}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input text: \"I love this shampoo, it makes my hair so shiny\"\n",
    "sentiment_input= {\"inputs\": \"Bu şampuanı seviyorum, saçlarımı çok parlak yapıyor\"}\n",
    "predictor_sentiment.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    "\n",
    "Taken from https://github.com/TQuad/turkish-nlp-qa-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/TQuad/turkish-nlp-qa-dataset/master/train-v0.1.json -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/TQuad/turkish-nlp-qa-dataset/master/dev-v0.1.json -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv train-v0.1.json data/train-v0.1.json\n",
    "!mv dev-v0.1.json data/dev-v0.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON files must be converted so that they can be used in a Q&A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "def convert_json(input_filename, output_filename):\n",
    "    with open(input_filename) as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        for article in dataset[\"data\"]:\n",
    "            title = article[\"title\"]\n",
    "            for paragraph in article[\"paragraphs\"]:\n",
    "                context = paragraph[\"context\"]\n",
    "                answers = {}\n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    question = qa[\"question\"]\n",
    "                    idx = qa[\"id\"]\n",
    "                    answers[\"text\"] = [a[\"text\"] for a in qa[\"answers\"]]\n",
    "                    answers[\"answer_start\"] = [int(a[\"answer_start\"]) for a in qa[\"answers\"]]\n",
    "                    f.write(\n",
    "                        json.dumps(\n",
    "                            {\n",
    "                                \"id\": idx,\n",
    "                                \"title\": title,\n",
    "                                \"context\": context,\n",
    "                                \"question\": question,\n",
    "                                \"answers\": answers,\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_json('data/train-v0.1.json', 'data/train.json')\n",
    "convert_json('data/dev-v0.1.json', 'data/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {}\n",
    "data_files[\"train\"] = 'data/train.json'\n",
    "data_files[\"validation\"] = 'data/val.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-45cc421ab74a1da8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-45cc421ab74a1da8/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48fc5154c5c42fb9b77d750674595a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece1bb40687546db9c41a3fc85ee25f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-45cc421ab74a1da8/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ee4178f3bd4be99e17b0d59bbc5636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>8348</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi'nin kurulma amacı nedir?</td>\n",
       "      <td>{'text': [' Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması '], 'answer_start': [75]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>8349</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevinin ne gibi amaçları vardır?</td>\n",
       "      <td>{'text': ['Gerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak'], 'answer_start': [661]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>8350</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.</td>\n",
       "      <td>İstanbul Üniversitesi Gözlemevi hangi amaçla açılmıştır?</td>\n",
       "      <td>{'text': ['Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla'], 'answer_start': [76]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                            title  \\\n",
       "7518  8348  İstanbul Üniversitesi Gözlemevi   \n",
       "7519  8349  İstanbul Üniversitesi Gözlemevi   \n",
       "7520  8350  İstanbul Üniversitesi Gözlemevi   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         context  \\\n",
       "7518  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "7519  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "7520  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi, 1933 yılında Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla açılmıştır. Gözlemsel astronomi konusunda çalışmalara evsahipliği yapan merkez;\\r\\n\\r\\nYıldız, güneş, uydu, astroid, kuyrukluyıldız, meteor, metorit ve tutulma gözlemleri yapmak ve gözlem verilerini değerlendirmek. \\r\\nDünyanın sayılı 200 gözlem veri merkezi ile 1939 yılından bu yana sürdürülen veri alışverişini sürdürmek. \\r\\nNASA, ESA gibi kuruluşların atmosfer dışından gözlem yapmak amacıyla uzaya gönderdiği yapay uydu verilerini alıp indirgemek ve değerlendirmek\\r\\nGerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak. gibi amaçlar gütmektedir.   \n",
       "\n",
       "                                                                                    question  \\\n",
       "7518  İstanbul Üniversitesi Gözlemevi Araştırma ve Uygulama Merkezi'nin kurulma amacı nedir?   \n",
       "7519  İstanbul Üniversitesi Gözlemevinin ne gibi amaçları vardır?                              \n",
       "7520  İstanbul Üniversitesi Gözlemevi hangi amaçla açılmıştır?                                 \n",
       "\n",
       "                                                                                                                                                                                                                    answers  \n",
       "7518  {'text': [' Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması '], 'answer_start': [75]}                                                                  \n",
       "7519  {'text': ['Gerek yurt dışından alınan gerekse İstanbul Üniversitesi Gözlemevi'nde elde edilen verileri kullanarak ve gerekli bilgisayar programlarını yazarak araştırmalar yapıp yayınlamak'], 'answer_start': [661]}  \n",
       "7520  {'text': ['Fen Fakültesi bünyesinde kurulan Astronomi ve Uzay Bilimleri Bölümü'nün araştırma ve gözlemlerinde kullanılması amacıyla'], 'answer_start': [76]}                                                           "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[7518:7521]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix_qa = 'datasets/turkish_qa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload failed: data/train.json to s3:////train.json Parameter validation failed:\n",
      "Invalid bucket name \"\": Bucket name must match the regex \"^[a-zA-Z0-9.\\-_]{1,255}$\" or be an ARN matching the regex \"^arn:(aws).*:(s3|s3-object-lambda):[a-z\\-0-9]+:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\\-]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\\-]{1,63}$\"\n",
      "upload failed: data/val.json to s3:////val.json Parameter validation failed:\n",
      "Invalid bucket name \"\": Bucket name must match the regex \"^[a-zA-Z0-9.\\-_]{1,255}$\" or be an ARN matching the regex \"^arn:(aws).*:(s3|s3-object-lambda):[a-z\\-0-9]+:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\\-]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\\-]{1,63}$\"\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp data/train.json s3://$sagemaker_session_bucket/$s3_prefix/train.json\n",
    "!aws s3 cp data/val.json s3://$sagemaker_session_bucket/$s3_prefix/val.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "hyperparameters_qa={\n",
    "    'model_name_or_path': model_name,\n",
    "    'train_file': '/opt/ml/input/data/train/train.json',\n",
    "    'validation_file': '/opt/ml/input/data/val/val.json',\n",
    "    'do_train': True,\n",
    "    'do_eval': False,\n",
    "    'fp16': True,\n",
    "    'per_device_train_batch_size': 4,\n",
    "    'per_device_eval_batch_size': 4,\n",
    "    'num_train_epochs': 2,\n",
    "    'max_seq_length': 384,\n",
    "    'pad_to_max_length': True,\n",
    "    'doc_stride': 128,\n",
    "    'output_dir': '/opt/ml/model'\n",
    "}\n",
    "\n",
    "instance_type = 'ml.p3.16xlarge'\n",
    "instance_count = 1\n",
    "volume_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_qa = HuggingFace(entry_point='run_qa.py',\n",
    "                                       source_dir='./scripts',\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       volume_size=volume_size,\n",
    "                                       role=role,\n",
    "                                       transformers_version='4.10',\n",
    "                                       pytorch_version='1.9',\n",
    "                                       py_version='py38',\n",
    "                                       hyperparameters=hyperparameters_qa,\n",
    "                                       disable_profiler=True,\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_qa.fit({'train': f's3://{sagemaker_session_bucket}/{s3_prefix_qa}/', 'val': f's3://{sagemaker_session_bucket}/{s3_prefix_qa}/'}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_qa = huggingface_estimator_qa.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    wait=False,\n",
    "    endpoint_name=\"turkish-qa-endpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only required to create a predictor from an already deployed model\n",
    "predictor_qa = HuggingFacePredictor('turkish-qa-endpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: \"When did he start a vagabond life?\"\n",
    "#Predicted answer: \"On his father's death\"\n",
    "\n",
    "data = {\n",
    "\"inputs\": {\n",
    "    \"question\": \"Ne zaman avare bir hayata başladı?\",\n",
    "    \"context\": \"\"\"ABASIYANIK, Sait Faik. Hikayeci (Adapazarı 23 Kasım 1906-İstanbul 11 Mayıs 1954). \\\n",
    "İlk öğrenimine Adapazarı’nda Rehber-i Terakki Mektebi’nde başladı. İki yıl kadar Adapazarı İdadisi’nde okudu.\\\n",
    "İstanbul Erkek Lisesi’nde devam ettiği orta öğrenimini Bursa Lisesi’nde tamamladı (1928). İstanbul Edebiyat \\\n",
    "Fakültesi’ne iki yıl devam ettikten sonra babasının isteği üzerine iktisat öğrenimi için İsviçre’ye gitti. \\\n",
    "Kısa süre sonra iktisat öğrenimini bırakarak Lozan’dan Grenoble’a geçti. Üç yıl başıboş bir edebiyat öğrenimi \\\n",
    "gördükten sonra babası tarafından geri çağrıldı (1933). Bir müddet Halıcıoğlu Ermeni Yetim Mektebi'nde Türkçe \\\n",
    "gurup dersleri öğretmenliği yaptı. Ticarete atıldıysa da tutunamadı. Bir ay Haber gazetesinde adliye muhabirliği\\\n",
    "yaptı (1942). Babasının ölümü üzerine aileden kalan emlakin geliri ile avare bir hayata başladı. Evlenemedi.\\\n",
    "Yazları Burgaz adasındaki köşklerinde, kışları Şişli’deki apartmanlarında annesi ile beraber geçen bu fazla \\\n",
    "içkili bohem hayatı ömrünün sonuna kadar sürdü.\"\"\"\n",
    "    }\n",
    "}\n",
    "predictor_qa.predict(data)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: \"When did Einstein return to Germany?\"\n",
    "#Predicted answer: \"1914\"\n",
    "\n",
    "data = {\n",
    "\"inputs\": {\n",
    "    \"question\": \"Ne zaman Almanya’ya döndü?\",\n",
    "    \"context\": \"\"\"1908’de artık oldukça tanınmış, büyük bir bilim adamı olarak tanınıyordu ve Bern \\\n",
    "Üniversitesinde öğretmen olarak atanmıştı. Sonraki sene patent ofisindeki işinden ve öğretmenlikten \\\n",
    "ayrıldı ve Zürih Üniversitesinde fizik doçentliğine başladı. 1911 yılında Prag’da Karl-Ferdinand \\\n",
    "Üniversitesinde profesörlük unvanı aldı. 1914 yılında Almanya’ya döndü, Kaiser Willhelm Fizik \\\n",
    "Enstitüsü’nde yönetici, Berlin Humboldt Üniversitesinde profesör oldu. Bu işlerindeki \\\n",
    "sözleşmelerinde öğretmenlik görevlerini oldukça azaltan maddeler vardı.\"\"\"\n",
    "    }\n",
    "}\n",
    "predictor_qa.predict(data)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
